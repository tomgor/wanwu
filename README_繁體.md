<div align="center">
  <img src="https://github.com/user-attachments/assets/6ceb4269-a861-4545-84db-bad322592156" style="width:45%; height:auto;" />
<p>
  <a href="#-核心功能模块">核心功能模組</a> •
  <a href="#-典型應用場景">典型應用場景</a> •
  <a href="#-快速開始">快速開始</a> •
  <a href="#-使用萬悟">使用萬悟</a> •
  <a href="#-q--a">Q & A</a> •
  <a href="#-聯繫我們">聯繫我們</a> 
</p>
<p>
  <img alt="License" src="https://img.shields.io/badge/license-apache2.0-blue.svg">
  <img alt="Go Version" src="https://img.shields.io/badge/go-%3E%3D%201.24.0-blue">
  </a>
  <a href="https://github.com/UnicomAI/wanwu/releases">
    <img alt="Release Notes" src="https://img.shields.io/github/v/release/UnicomAI/wanwu?label=Release&logo=github&color=green">
  </a>
</p>
<p align="center">
    <a href="https://github.com/UnicomAI/wanwu/blob/main/README.md">English</a> |
    <a href="https://github.com/UnicomAI/wanwu/blob/main/README_CN.md">简体中文</a> |
    繁體中文
</p>
</div>


&emsp;&emsp;**元景萬悟智能體平台**是一款面向**企業級**場景的**一站式**、**商用license友好**的**智能體開發平台**，致力於為企業提供安全、高效、合規的一站式AI解決方案。我們以「技術開放、生態共建」為核心理念，透過整合大語言模型、業務流程自動化等前沿技術，構建了覆蓋模型全生命週期管理、MCP、聯網檢索、智能體快速開發、企業知識庫建設、複雜工作流編排等完整功能體系的AI工程化平台。平台採用模組化架構設計，支援靈活的功能擴展和二次開發，在確保企業數據安全和隱私保護的同時，大幅降低了AI技術的應用門檻。無論是中小型企業快速構建智能化應用，還是大型企業實現複雜業務場景的智能化改造，元景萬悟智能體平台都能提供強有力的技術支撐，助力企業加速數字化轉型進程，實現降本增效和業務創新。

------

<div>
  <p align="center">
    <a href="https://www.bilibili.com/video/BV1HxpazNEAM"><img width="600" src="https://github.com/user-attachments/assets/54efe5d3-c28d-48fb-9a6e-d6ac536a1f95" /></a>
  </p>
</div>

------

### &#x1F525; 採用寬鬆友好的 Apache 2.0 License，支援開發者自由擴展與二次開發
✔ **企業級工程化**：提供從模型納管到應用落地的完整工具鏈，解決LLM技術落地「最後一公里」問題  

✔ **開放開源生態**：採用寬鬆友好的 **Apache 2.0 License**，支援開發者自由擴展與二次開發  

✔ **全棧技術支援**：配備專業團隊為生態夥伴提供 **架構諮詢、性能優化** 全週期賦能  

✔ **多租戶架構**：提供多租戶帳號體系，滿足用戶成本控制、數據安全隔離、業務彈性擴展、行業定制化、快速上線及生態協同等核心需求

✔ **信創適配**：已適配國產信創資料庫TiDB和OceanBase

------

### 🚩 核心功能模組
**1. 模型納管（Model Hub）**

▸ 支援 **數百種專有/開源大模型**（包括GPT、Claude、Llama等系列）的統一接入與生命週期管理

▸ 深度適配 **OpenAI API 標準** 及 **聯通元景** 生態模型，實現異構模型的無縫切換

▸ 提供 **多推理後端支援**（vLLM、TGI等）與 **自託管解決方案**，滿足不同規模企業的算力需求

#### **2. MCP**
▸ **標準化介面**：使 AI 模型能夠無縫連接各種外部工具（如 GitHub、Slack、資料庫等），而無需為每個數據源單獨開發適配器

▸ **內置豐富精選推薦**：整合100+行業MCP介面，讓用戶方便快捷，輕鬆調用

#### **3. 聯網檢索**（Web Search）
▸ **即時信息獲取**：具備強大的聯網檢索能力，能夠即時從互聯網獲取最新的信息。在問答場景中，當用戶的問題需要最新的新聞、數據等信息時，平台可以快速檢索並返回準確的結果，提升回答的時效性和準確性

▸ **多源數據整合**：整合了多種互聯網數據源，包括新聞網站、學術資料庫、行業報告等。透過對多源數據的整合和分析，為用戶提供更全面、更深入的信息。例如，在市場調研場景中，可以同時從多個數據源獲取相關數據，進行綜合分析和評估

▸ **智能檢索策略**：採用智能檢索算法，根據用戶的問題自動優化檢索策略，提高檢索效率和準確性。支援關鍵詞檢索、語義檢索等多種檢索方式，滿足不同用戶的需求。同時，對檢索結果進行智能排序和篩選，優先展示最相關、最有價值的信息

#### **4. 可視化工作流（Workflow Studio）**
▸ 透過 **低程式碼拖拽畫布** 快速構建複雜AI業務流程

▸ 內置 **條件分支、API、大模型、知識庫、程式碼、MCP** 等多種節點，支援端到端流程調試與性能分析

#### **5. 企業級知識庫、RAG Pipeline**
▸ 提供**知識庫創建**→ **文檔解析→向量化→檢索→精排** 的全流程知識管理能力，支援pdf/docx/txt/xlsx/csv/pptx等 **多種格式** 文檔，還支援網頁資源的抓取和接入

▸ 整合 **多模態檢索** 、**級聯切分** 與 **自適應切分**，顯著提升問答準確率

#### **6. 智能體開發框架（Agent Framework）**
▸ 可基於 **函數調用（Function Calling）** 的Agent構建範式，支援工具擴展、私域知識庫關聯與多輪對話

▸ 支援**線上調試**

#### **7. 後端即服務（BaaS）**
▸ 提供 **RESTful API** ，支援與企業現有系統（OA/CRM/ERP等）深度整合

▸ 提供 **細粒度權限控制**，保障生產環境穩定運行

------

### &#x1F4E2; 功能比較
|    功能     | 元景萬悟智能體平台 |       Dify.AI       |     Fastgpt     |       Ragflow       |     Coze開源版      |
| :---------: | :----------------: | :-----------------: | :-------------: | :-----------------: | :-----------------: |
|  模型導入   |         ✅          |          ✅          |   ❌(內置模型)   |          ✅          |     ❌(內置模型)     |
|   RAG引擎   |         ✅          |          ✅          |        ✅        |          ✅          |          ✅          |
|     MCP     |         ✅          |          ✅          |        ✅        | ✅（需安裝工具使用） |          ❌          |
| 直接導入OCR |         ✅          |          ❌          |        ❌        |          ❌          |          ❌          |
|  搜索增強   |         ✅          | ✅（需安裝工具使用） |        ✅        | ✅（需安裝工具使用） |          ✅          |
|    Agent    |         ✅          |          ✅          |        ✅        |          ✅          |          ✅          |
|   工作流    |         ✅          |          ✅          |        ✅        |          ✅          |          ✅          |
|  本地部署   |         ✅          |          ✅          |        ✅        |          ✅          |          ✅          |
| license友好 |         ✅          |   ❌（商用有限制）   | ❌（商用有限制） |     未完全開源      |          ✅          |
|   多租戶    |         ✅          |   ❌（商用有限制）   | ❌（商用有限制） |          ✅          | ✅（但用戶間不互通） |
> 截止2025年8月1日對比。
------
### &#x1F3AF; 典型應用場景
- **智能客服**：基於RAG+Agent實現高準確率的業務諮詢與工單處理  
- **知識管理**：構建企業專屬知識庫，支援語義搜索與智能摘要生成  
- **流程自動化**：透過工作流引擎實現合同審核、報銷審批等業務的AI輔助決策  
平台已成功應用於 **金融、工業、政務** 等多個行業，助力企業將LLM技術的理論價值轉化為實際業務收益。我們誠邀開發者加入開源社區，共同推動AI技術的民主化進程。  
------
### 🚀 快速開始
- 元景萬悟智能體平台的工作流模組使用的是以下項目，可到其倉庫查看詳情。
  - v0.1.8及以前：[wanwu-agentscope](https://github.com/UnicomAI/wanwu-agentscope.git) 項目
  - v0.2.0開始：[wanwu-workflow](https://github.com/UnicomAI/wanwu-workflow/tree/dev/wanwu-backend) 項目
- **Docker安裝（推薦）**
1. 首次運行前

    1.1 拷貝環境變量文件

    ```bash
    cp .env.bak .env
    ```
    1.2 根據系統修改.env文件中的`WANWU_ARCH`、`WANWU_EXTERNAL_IP`變量
    ```
    # amd64 / arm64
    WANWU_ARCH=amd64
    
    # external ip port（注意如果瀏覽器訪問非localhost部署的萬悟，則需要修改localhost為對外ip，例如192.168.xx.xx）
    WANWU_EXTERNAL_IP=localhost
    ```
    1.3 創建docker運行網絡
    ```
    docker network create wanwu-net
    ```

2. 啟動服務（首次運行會自動從Docker Hub拉取鏡像）
    ```bash
    # amd64系統執行:
    docker compose --env-file .env --env-file .env.image.amd64 up -d
    # arm64系統執行:
    docker compose --env-file .env --env-file .env.image.arm64 up -d
    ```

3. 登錄系統：http://localhost:8081
    ```
    默認用戶：admin
    默認密碼：Wanwu123456
    ```

4. 關閉服務
    ```bash
    # amd64系統執行:
    docker compose --env-file .env --env-file .env.image.amd64 down
    # arm64系統執行:
    docker compose --env-file .env --env-file .env.image.arm64 down
    ```
- **源碼啟動（開發）**
1. 基於上述Docker安裝步驟，將系統服務完整啟動
2. 以後端bff-service服務為例
    2.1 停止bff-service
    ```
    make -f Makefile.develop stop-bff
    ```
    2.2 編譯bff-service可執行文件
    ```
    # amd64系統執行:
    make build-bff-amd64
    # arm64系統執行:
    make build-bff-arm64
    ```
    2.3 啟動bff-service
    ```
    make -f Makefile.develop run-bff
    ```
------
### ⬆️ 版本升級
1. 基於上述Docker安裝步驟，將系統服務完整停止
2. 更新至最新版本代碼
    2.1 wanwu倉庫目錄內，更新代碼
    ```bash
    # 切換到main分支
    git checkout main
    # 拉取最新代碼
    git pull
    ```
    2.2 重新拷貝環境變量文件（如果有環境變量修改，請自行重新修改）
    ```bash
    # 備份當前.env文件
    cp .env .env.old
    # 拷貝.env文件
    cp .env.bak .env
    ```
3. 基於上述Docker安裝步驟，將系統服務完整啟動
------
### &#x1F4D1; 使用萬悟
為了幫助您快速上手本項目，我們強烈推薦先查看[ 文檔操作手冊](https://github.com/UnicomAI/wanwu/tree/main/configs/microservice/bff-service/static/manual)。我們為用戶提供了交互式、結構化的操作指南，您可以直接在其中查看操作說明、接口文檔等，極大地降低了學習和使用的門檻。詳細功能清單如下：

以下是您提供的 Markdown 表格內容的繁體中文翻譯，保留原有格式與連結：
|                             功能                             |                           詳細描述                           |
| :----------------------------------------------------------: | :----------------------------------------------------------: |
| [模型管理](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/1.%E6%A8%A1%E5%9E%8B%E7%AE%A1%E7%90%86.md) | 支援使用者匯入包括聯通元景、OpenAI-API-compatible、Ollama、通義千問、火山引擎等模型供應商的 LLM、Embedding、Rerank 模型。[ 模型匯入方式-詳細版](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/%E6%A8%A1%E5%9E%8B%E5%AF%BC%E5%85%A5%E6%96%B9%E5%BC%8F-%E8%AF%A6%E7%BB%86%E7%89%88.md) |
| [知識庫](https://github.com/UnicomAI/wanwu/tree/main/configs/microservice/bff-service/static/manual/2.%E7%9F%A5%E8%AF%86%E5%BA%93) | 在文件解析能力方面：支援12種文件類型的上傳，支援 URL 解析；文件解析方式支援 OCR 和[ 高精度模型解析（標題/表格/公式）](https://github.com/UnicomAI/DocParserServer/tree/main)，文件分段設定支援通用分段和父子分段。在調優能力方面：支援元數據管理及元數據過濾查詢，支援分段內容增刪改，支援對分段設定關鍵字標籤提升召回效果，支援分段啟停操作，支援命中測試等功能。在檢索能力方面：支援向量檢索、全文檢索、混合檢索等多種檢索模式；在問答能力方面：支援自動引用出處，支援圖文並茂的生成答案。 |
| [資源庫](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/3.%E5%B7%A5%E5%85%B7%E5%B9%BF%E5%9C%BA.md) | 同時支援匯入自己的 MCP 服務或自訂工具，並在工作流和智能體中使用。 |
| [安全護欄](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/4.%E5%AE%89%E5%85%A8%E6%8A%A4%E6%A0%8F.md) |      使用者可以建立敏感詞表，控制模型回饋結果的安全性。      |
| [文本問答](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/5.%E6%96%87%E6%9C%AC%E9%97%AE%E7%AD%94.md) | 基於私人知識庫的專屬知識顧問，支援知識庫管理、知識問答、知識總結、個性參數配置、安全護欄、檢索配置等功能，提高知識管理與學習的效率。支援公開或私密發布文本問答應用，支援發布為 API。 |
| [工作流](https://github.com/UnicomAI/wanwu/tree/main/configs/microservice/bff-service/static/manual/6.%E5%B7%A5%E4%BD%9C%E6%B5%81) | 可擴展智能體能力邊界，由節點組成，提供視覺化工作流編輯能力，使用者可編排多個不同的工作流節點，實現複雜且穩定的業務流程。支援公開或私密發布工作流應用，支援發布為 API，支援匯入匯出。 |
| [智能體](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/7.%E6%99%BA%E8%83%BD%E4%BD%93.md) | 基於使用者使用場景和業務需求建立智能體，支援選模型、設定提示詞、聯網檢索、知識庫選擇、MCP、工作流、自訂工具等。支援公開或私密發布智能體應用，支援發布為 API 和 Web Url。 |
| [應用廣場](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/8.%E5%BA%94%E7%94%A8%E5%B9%BF%E5%9C%BA.md) |  支援使用者體驗已發布的應用，包括文本問答、工作流和智能體。  |
| [MCP廣場](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/9.MCP%E5%B9%BF%E5%9C%BA.md) |          內建 100+ 精選行業 MCP server，即選即用。           |
| [設定](https://github.com/UnicomAI/wanwu/blob/main/configs/microservice/bff-service/static/manual/9.%E8%AE%BE%E7%BD%AE.md) | 平台支援多租戶，允許使用者進行組織、角色、使用者管理、平台基礎配置。 |

------
### &#x1F4F0; TODO LIST
- [ ] 多模態模型接入
- [ ] 支援自定義MCP Server，即可以把工作流、智能體、或者符合OpenAPI規範的API作為tools添加到MCP Server裡進行發布
- [ ] 知識庫共享
- [ ] 智能體和模型測評
- [ ] 智能體監控統計
- [ ] 模型體驗
- [ ] 提示詞工程
------
### &#128172; Q & A
- **【Q】Linux系統Elastic(elastic-wanwu)啟動報錯：Memory limited without swap.**
    【A】關閉服務，執行 `sudo sysctl -w vm.max_map_count=262144` 後，重啟服務
    
- **【Q】系統服務正常啟動後，mysql-wanwu-setup和elastic-wanwu-setup容器退出：狀態碼為Exited (0)**
    【A】正常，這兩個容器用於完成一些初始化任務，執行完成後會自動退出
    
- **【Q】模型導入相關**
    【A】以導入聯通元景LLM為例（導入OpenAI-API-compatible或導入Embedding、Rerank類型類似）：
    ```
    1. 聯通元景MaaS雲LLM的Open API接口例如：https://maas.ai-yuanjing.com/openapi/compatible-mode/v1/chat/completions
    
    2. 用戶在聯通元景MaaS雲上申請到的API Key形如：sk-abc********************xyz
    
    3. 確認API與Key可正確請求LLM，以請求yuanjing-70b-chat為例：
        curl --location 'https://maas.ai-yuanjing.com/openapi/compatible-mode/v1/chat/completions' \
        --header 'Content-Type: application/json' \
        --header 'Accept: application/json' \
        --header 'Authorization: Bearer sk-abc********************xyz' \
        --data '{
                "model": "yuanjing-70b-chat",
                "messages": [{
                        "role": "user",
                        "content": "你好"
                }]
        }'
    
    4. 導入模型：
    4.1【模型名稱】必須為上述curl中可以正確請求的model；例如 yuanjing-70b-chat
    4.2【API Key】必須為上述curl中可以正確請求的key；例如 sk-abc********************xyz（注意不填Bearer前綴）
    4.3【推理URL】必須為上述curl中可以正確請求的url；例如 https://maas.ai-yuanjing.com/openapi/compatible-mode/v1（注意不帶 /chat/completions 後綴）
    
    5. 導入Embedding模型同上述導入LLM，注意推理URL不帶 /embeddings 後綴
    
    6. 導入Rerank模型同上述導入LLM，注意推理URL不帶 /rerank 後綴
    ```
------
### &#x1F517; 致謝
- [Coze](https://github.com/coze-dev)
- [LangChain](https://github.com/langchain-ai/langchain)
- [Qwen-Agent](https://github.com/QwenLM/Qwen-Agent)
------
### ⚖️ 許可證
元景萬悟智能體平台根據Apache License 2.0發布。

### &#x1F4E9; 聯繫我們
| QQ 群1(已滿):490071123                                    | QQ 群2:1026898615                                         |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| <img width="183" height="258" alt="image" src="https://github.com/user-attachments/assets/010f1d68-78e9-446d-baf1-0a7339efb48e" /> | <img width="183" height="258" alt="image" src="https://github.com/user-attachments/assets/10796f69-5c18-4f21-adbb-b22b6ef88df2" /> |
